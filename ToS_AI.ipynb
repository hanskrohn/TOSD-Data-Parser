{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToS-AI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4LoCmkpFQbfS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hk72/TOSD-Data-Parser/blob/db-cleaning-work/ToS_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYI9o0FoQNYr"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DI6wn2kDGqi"
      },
      "source": [
        "%%capture\n",
        "!pip3 install pymongo[srv]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt_Ea4HEDOma"
      },
      "source": [
        "Import relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq2qsHZeDODW"
      },
      "source": [
        "from absl import logging\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "import dns # allows use of mongo URI  \n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from bson.objectid import ObjectId # Allows us to build ObjectId objects\n",
        "\n",
        "import xgboost as xgb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK3X7p_l5EAX"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMflVuZZ5CuO",
        "outputId": "47dbc49e-923a-4655-f855-e1eba757a798"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUsIT2e2UHrA"
      },
      "source": [
        "Load Google Universal Sentence Encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKFIMMg_UMhH",
        "outputId": "ea448b8e-5a11-4165-8491-2972b32be8ac"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "sentence_encoder_model = hub.load(module_url)\n",
        "print (f\"module {module_url} loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiOM3UKaF-Wa"
      },
      "source": [
        "Hardcode ENV variable **Change when local\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qk7xXzGD62"
      },
      "source": [
        "ENV = {\n",
        "    \"mongoUsername\": \"hk72\",\n",
        "    \"mongoPassword\": \"CapstoneProject2021\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo7lJ6r7jqFW"
      },
      "source": [
        "Connect to Mongo DB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-mm417bjuwm",
        "outputId": "9f5e7ca9-7560-4e70-94bc-b86efbe86fd7"
      },
      "source": [
        "username = ENV[\"mongoUsername\"]\n",
        "password = ENV[\"mongoPassword\"]\n",
        "client = pymongo.MongoClient(f\"mongodb+srv://{username}:{password}@cluster0.bildb.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")\n",
        "\"mongodb+srv://hk72:CapstoneProject2021@cluster0.bildb.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\"\n",
        "\n",
        "print(client.list_database_names())\n",
        "db = client.myFirstDatabase\n",
        "\n",
        "print(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['myFirstDatabase', 'admin', 'local']\n",
            "Database(MongoClient(host=['cluster0-shard-00-02.bildb.mongodb.net:27017', 'cluster0-shard-00-00.bildb.mongodb.net:27017', 'cluster0-shard-00-01.bildb.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='atlas-ez68e0-shard-0', ssl=True), 'myFirstDatabase')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPsbs3a_T9-x"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZRITvx2T_6W"
      },
      "source": [
        "def embed(input):\n",
        "  return sentence_encoder_model(input)\n",
        "\n",
        "def print_embeddings(sentences, embeddings_list):\n",
        "  for i, sentence_embedding in enumerate(np.array(embeddings_list).tolist()):\n",
        "    print(\"Sentence: {}\".format(sentences[i]))\n",
        "    print(\"Embedding size: {}\".format(len(sentence_embedding)))\n",
        "    sentence_embedding_snippet = \", \".join(\n",
        "        (str(x) for x in sentence_embedding[:3]))\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(sentence_embedding_snippet))\n",
        "\n",
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvqwmBwUWhlU"
      },
      "source": [
        "Define custom helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrQMzd0IWzty"
      },
      "source": [
        "\"\"\"\n",
        "Compute the average similarity between a case\n",
        "and all snippets that map to that case\n",
        "RETURN: int, average similarity between case text and each snippet text\n",
        "\"\"\"\n",
        "def avg_sim_to_case(case_embedding, snippet_embeddings):\n",
        "  \n",
        "  similarity_arr = [] # store similarity values between snippet and case\n",
        "  average_similarity = 0\n",
        "  \n",
        "  for snippet_embedding in snippet_embeddings:\n",
        "    similarity = np.inner(snippet_embedding, case_embedding)\n",
        "    similarity_arr.append(similarity)\n",
        "  \n",
        "  average_similarity = np.average(similarity_arr)\n",
        "\n",
        "  return average_similarity\n",
        "\n",
        "\"\"\"\n",
        "Parse out text for all cases and the snippets that map to that case\n",
        "RETURN: list of objects of form {case_test: \"\", service_snippets=[\"\",\"\"]}\n",
        "\"\"\"\n",
        "def get_all_cases_snippets_text():\n",
        "  cases_snippets_text_arr = [] \n",
        "  \n",
        "  collection = db.cleaneddataswithexclusion\n",
        "\n",
        "  cases = list(collection.find())\n",
        "\n",
        "  for doc in cases:\n",
        "    case_dict = {}\n",
        "    case_text = \"\"\n",
        "    service_snippets = []\n",
        "\n",
        "    case_text = doc[\"case\"]\n",
        "\n",
        "    snippets_arr = doc[\"snippets\"]\n",
        "\n",
        "    if len(snippets_arr) < 5:\n",
        "      continue\n",
        "\n",
        "    for snippet in snippets_arr:\n",
        "      snippet_text = snippet[\"quoteText\"]\n",
        "      service_snippets.append(snippet_text)\n",
        "\n",
        "    case_dict[\"case_text\"] = case_text\n",
        "    case_dict[\"service_snippets\"] = service_snippets\n",
        "    cases_snippets_text_arr.append(case_dict)\n",
        "  \n",
        "  return cases_snippets_text_arr\n",
        "\n",
        "\"\"\"\n",
        "Convert text to embeddings for all cases and snippets that map to that case\n",
        "RETURN: list of objs in form {case_embedding: [], service_snippet_embeddings=[[],[]]} \n",
        "\"\"\"\n",
        "def get_all_cases_snippets_embeddings(cases_snippets_text_arr):\n",
        "  \n",
        "  cases_snippets_embeddings_arr = [] \n",
        "  \n",
        "  for case in cases_snippets_text_arr:\n",
        "    case_embedded_dict = {}\n",
        "    \n",
        "    case_embedding = embed([case[\"case_text\"]])\n",
        "    service_snippet_embeddings = embed(case[\"service_snippets\"])\n",
        "\n",
        "    case_embedded_dict[\"case_embedding\"] = case_embedding\n",
        "    case_embedded_dict[\"case_text\"] = case[\"case_text\"]\n",
        "    case_embedded_dict[\"service_snippet_embeddings\"] = service_snippet_embeddings\n",
        "\n",
        "    cases_snippets_embeddings_arr.append(case_embedded_dict)\n",
        "\n",
        "  return cases_snippets_embeddings_arr\n",
        "\n",
        "\"\"\"\n",
        "Print a summary including: Case text, number of service snippets that map to it,\n",
        "  average similarity of case text to snippet (for each case)\n",
        "RETURN: none\n",
        "\"\"\"\n",
        "def print_summary(cases_snippets_embeddings_arr): #probably translate this to a dataframe instead\n",
        "  for embedded_case in cases_snippets_embeddings_arr:\n",
        "    average_similarity = avg_sim_to_case(embedded_case[\"case_embedding\"],embedded_case[\"service_snippet_embeddings\"])\n",
        "    \n",
        "    print(\"Case text: \" + embedded_case[\"case_text\"])\n",
        "    print(\"Number of service snippets: \", len(embedded_case[\"service_snippet_embeddings\"]))\n",
        "    print(\"Average similarity of snippet to case: \", average_similarity)\n",
        "    print(\"________________________________________________________\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Saz6Hz5Yr9b"
      },
      "source": [
        "Create folder for current model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpF7kBD5Y1_m"
      },
      "source": [
        "training_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "os.mkdir(f\"/content/drive/MyDrive/Capstone/Models and Reports/{training_datetime}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LoCmkpFQbfS"
      },
      "source": [
        "# Hard-coded Dry Run\n",
        "Skip this section for ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTsl-50DMCeR"
      },
      "source": [
        "Get case text and snippets from DB "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WkD0_JMHKL"
      },
      "source": [
        "case_text = \"\"\n",
        "service_snippets = []\n",
        "collection = db.cleaneddataswithexclusion\n",
        "\n",
        "cookiesID = ObjectId(\"60cc1f22fc727e40b42439cf\") # ID for cookies case\n",
        "\n",
        "doc = collection.find( {'_id' : cookiesID })\n",
        "\n",
        "case_text = doc[0][\"case\"] # treat returned cursor as Dict becuase it contains single obj\n",
        "\n",
        "snippets_arr = doc[0][\"snippets\"]\n",
        "\n",
        "for snippet in snippets_arr:\n",
        "  snippet_text = snippet[\"quoteText\"]\n",
        "  service_snippets.append(snippet_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RMObhkGQvFT"
      },
      "source": [
        "Create embeddings for case text and snippets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owfZpfobRIeD"
      },
      "source": [
        "case_embedding = embed([case_text])\n",
        "snippet_embeddings = embed(service_snippets)\n",
        "\n",
        "print_embeddings([case_text], case_embedding)\n",
        "\n",
        "print_embeddings(service_snippets, snippet_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE1s_V3PTtfp"
      },
      "source": [
        "Visualize similarity within specific case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM7DRheSTxSe"
      },
      "source": [
        "# plot_similarity(service_snippets, snippet_embeddings, 90) # Plot similarity with service text as labels\n",
        "\n",
        "enumeration = list(range(1, len(service_snippets)))\n",
        "plot_similarity(enumeration, snippet_embeddings, 90) # Plot similarity with enumerated snippets as labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrRA6LZWYPv5"
      },
      "source": [
        "Check snippets similarity with case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljMmMXrVYTIt"
      },
      "source": [
        "avg_sim_to_case(case_embedding, snippet_embeddings)\n",
        "\n",
        "# avg_sim_to_case([.5, .5, .5], [[.6, .6, .6], [.6, .6, .6], [.6, .6, .6]]) # sanity check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niHr_fjwh3mD"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Create workable objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhcnUy6h89s"
      },
      "source": [
        "Get all case and snippet text - Starting point for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrnCSy18iJqt",
        "outputId": "c1c9c83d-c3a2-42a2-afc3-2a97c3fe0157"
      },
      "source": [
        "cases_snippets_text_arr = get_all_cases_snippets_text() # List of objs in form {case_text: \"\", service_snippets=[\"\",\"\"]} \n",
        "print(len(cases_snippets_text_arr))\n",
        "cases_snippets_embeddings_arr = get_all_cases_snippets_embeddings(cases_snippets_text_arr) # List of objs in form {case_text:\"\", case_embedding: [], service_snippet_embeddings=[[],[]]} \n",
        "\n",
        "# Save summary of data\n",
        "summary_df = pd.DataFrame([[case[\"case_text\"], len(case[\"service_snippets\"])] for case in cases_snippets_text_arr])\n",
        "summary_df.to_csv(f\"/content/drive/MyDrive/Capstone/Models and Reports/{training_datetime}/Data_Summary.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ4wpE79CRVF"
      },
      "source": [
        "# Attempt Machine Learning Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDKRdEi9CPxe"
      },
      "source": [
        "NOTE: See input object below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiVuucQBCPiQ"
      },
      "source": [
        "\"\"\"\n",
        "[\n",
        " {\n",
        "      \n",
        "    case_embedding: [x1, x2, ..., x512], \n",
        "    service_snippet_embeddings=[[x1, x2, ..., x512],[y1, y2, ..., y512], ... [zzz1, zzz2, ..., zzz512]]\n",
        "  } \n",
        "]\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11zC3AfdDdb4"
      },
      "source": [
        "# XGBoost Supervised Learning - Consistent Weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apuw1ZypO_H5"
      },
      "source": [
        "Play around with numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D61p2mxO-z0",
        "outputId": "ffe4eba6-b1f2-4ef2-be62-c098c7be0f30"
      },
      "source": [
        "print(type(cases_snippets_embeddings_arr[0][\"service_snippet_embeddings\"].numpy()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0NjmCGAJUeE"
      },
      "source": [
        "Convert tenors to 2D numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYZx1MUnQblv",
        "outputId": "42a4a5df-b4ef-4ba4-fe40-890eeca8dad6"
      },
      "source": [
        "#List variables to temporarily hold features and labels\n",
        "data_arr = []\n",
        "labels_arr = []\n",
        "\n",
        "# print(type(cases_snippets_embeddings_arr[0][\"service_snippet_embeddings\"].numpy()[0]))\n",
        "# print(cases_snippets_embeddings_arr[0][\"service_snippet_embeddings\"].numpy()[0].shape)\n",
        "\n",
        "# Bullshit brute force because I don't have time\n",
        "for case_obj in cases_snippets_embeddings_arr:\n",
        "  for service_snippet in case_obj[\"service_snippet_embeddings\"].numpy():\n",
        "    # labels_arr.append(case_obj[\"case_text\"])\n",
        "    data_arr.append(service_snippet)\n",
        "    labels_arr.append(case_obj[\"case_text\"])\n",
        "  \n",
        "#Convert lists to numpy arrays\n",
        "data = np.array(data_arr)  # Numpy array of embedding vectors\n",
        "label = np.array(labels_arr)  # String targets\n",
        "\n",
        "print(\"Num samples: \", len(data_arr))\n",
        "print(\"Num labels: \", len(labels_arr)) # Num should be same for samples and labels\n",
        "\n",
        "print(\"Samples shape \", data.shape) # Should be 2d\n",
        "print(\"Labels shape \", label.shape) # Should be 1d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num samples:  12281\n",
            "Num labels:  12281\n",
            "Samples shape  (12281, 512)\n",
            "Labels shape  (12281,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00thUCBIQKVG"
      },
      "source": [
        "Create ordinal encoding for label set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cUBg7eRQNZE",
        "outputId": "090425c1-3de7-4918-e261-1b36000fee5f"
      },
      "source": [
        "label_encoder =  preprocessing.LabelEncoder()\n",
        "label_ordinal = label_encoder.fit_transform(label) # encode label set as integers\n",
        "print(label_ordinal.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12281,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyBWMb5MJi4u"
      },
      "source": [
        "Train basic classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-IylajuJj0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340c7865-4ac8-4af9-b70c-9c54f1fc64e3"
      },
      "source": [
        "seed = 7 # ensures that split is reproducible\n",
        "test_size = 0.20 # split of training vs testing data\n",
        "\n",
        "# todo add stratifying\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label_ordinal, test_size=test_size, random_state=seed)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9824\n",
            "9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx-xrvsHbt0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c248d438-67aa-4e10-f73f-202cf5ff1712"
      },
      "source": [
        "# fit model on training data\n",
        "model = xgb.XGBClassifier()\n",
        "print(len(labels_arr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d808ffcc6c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWimL4XuFuN5"
      },
      "source": [
        "dtrain = xgb.DMatrix(X_train, y_train)\n",
        "param = {'max_depth':7, 'n_estimators':1000, 'eta':1, 'verbosity':3, 'objective':'multi:softmax', 'num_class': len(labels_arr) }\n",
        "num_round = 2\n",
        "bst = xgb.train(param, dtrain, num_round)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSUWyvDMHXkC"
      },
      "source": [
        "model = bst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrHTJiyRH7OR"
      },
      "source": [
        "def call(model, inf):\n",
        "    return model.predict(xgb.DMatrix(inf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWnecpBcGK9F"
      },
      "source": [
        "Save serialized model to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTQvA2fCJP43"
      },
      "source": [
        "with open(f\"/content/drive/MyDrive/Capstone/Models and Reports/{training_datetime}/model.pickle.dat\", \"wb\") as ofile:\n",
        "  pickle.dump(model, ofile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wws6qnxokRBs"
      },
      "source": [
        "Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S6QaB-_kSgL",
        "outputId": "5b955dfc-f73e-4d1e-d540-f25ad8e75f91"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred = call(model, X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 26.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgQg__7C72l0"
      },
      "source": [
        "Get classification report and save to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I89f7CXtKZgw",
        "outputId": "ac7e46df-613f-430a-c73b-eba1596c1954"
      },
      "source": [
        "# Transform ordinal labels to case text \n",
        "test_labels = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Create list for target labels\n",
        "target_names = set(labels_arr).intersection(set(test_labels))\n",
        "target_names = list(target_names)\n",
        "\n",
        "# Create pandas dataframe for classification report\n",
        "classification_report_arr = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "classification_report_df = pd.DataFrame(classification_report_arr).transpose()\n",
        "\n",
        "# Save classification report as CSV\n",
        "classification_report_df.to_csv(f'/content/drive/MyDrive/Capstone/Models and Reports/{training_datetime}/Classification_Report.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCftkLUGvzvI"
      },
      "source": [
        "Build confusion matrix and save to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6zuXOZANOX-"
      },
      "source": [
        "y_true = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "y_pred_int = [int(x) for x in y_pred]\n",
        "y_pred_text = label_encoder.inverse_transform(y_pred_int)\n",
        "\n",
        "confusion_numpy = confusion_matrix(y_true, y_pred_text, labels=target_names)\n",
        "\n",
        "confusion_df = pd.DataFrame(data=confusion_numpy)\n",
        "\n",
        "confusion_df.to_csv(f'/content/drive/MyDrive/Capstone/Models and Reports/{training_datetime}/Confusion_Matrix.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrI_OB35WwdN"
      },
      "source": [
        "Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxdE8t9Etrjg"
      },
      "source": [
        "# load serialized model from file\n",
        "model_datetime = \"20210711160526\"\n",
        "loaded_model = pickle.load(open(f\"/content/drive/MyDrive/Capstone/Models and Reports/{model_datetime}/model.pickle.dat\", \"rb\"))\n",
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZITz5M87WgbX"
      },
      "source": [
        "\n",
        "loaded_model = pickle.load(open(\"20210710-XGBoost-2-25.pickle.dat\", \"rb\"))\n",
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1YqCgWWXe1H"
      },
      "source": [
        "Test model with new string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQdzeUZDXgZ8"
      },
      "source": [
        "test_text = \"This service will use your cookies how it wishes.\"\n",
        "test_embedding = embed([test_text])\n",
        "\n",
        "# Convert to numpy array\n",
        "test_numpy = test_embedding.numpy()\n",
        "\n",
        "#Create DMatrix\n",
        "dtest = xgb.DMatrix(test_numpy)\n",
        "\n",
        "prediction_num = loaded_model.predict(dtest)\n",
        "\n",
        "print(prediction_num)\n",
        "\n",
        "label_encoder.inverse_transform([int(prediction_num)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpy8azKMWomr"
      },
      "source": [
        "Test Loaded model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yQ_Mvz5WqYS"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred = call(loaded_model, X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}